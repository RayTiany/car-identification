{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8f00f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from cv2 import dnn_superres\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8a3aac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('*.jpg')\n",
    "data = pd.DataFrame(images, columns=['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "161a2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['brand'] = data['src'].apply(lambda x : x.split('_')[0].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "10e7db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = data[data['brand']=='BMW'][:50]\n",
    "d2 = data[data['brand']=='Audi'][:50]\n",
    "d3 = data[data['brand']=='Nissan'][:50] \n",
    "d4 = data[data['brand']=='Mercedes-Benz'][:50] \n",
    "d5 = data[data['brand']=='Honda'][:50] \n",
    "\n",
    "frames = [d1, d2, d3, d4, d5]\n",
    "\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    \"BMW\": 0,\n",
    "    \"Audi\": 1,\n",
    "    \"Mercedes-Benz\": 2,\n",
    "    \"Nissan\": 3,\n",
    "    \"Honda\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3295e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_resolution(images):\n",
    "    sr = dnn_superres.DnnSuperResImpl_create()\n",
    "    new_images_list = []\n",
    "    path = \"FSRCNN_x4.pb\"\n",
    "    sr.readModel(path)\n",
    "    sr.setModel(\"fsrcnn\", 4)\n",
    "    for image in images:\n",
    "        new_image = cv2.resize(image, dsize = (256, 256), interpolation=cv2.INTER_AREA)\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
    "        result = sr.upsample(new_image)\n",
    "        new_images_list.append(result)\n",
    "    return new_images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>brand</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...</td>\n",
       "      <td>Honda</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...</td>\n",
       "      <td>Honda</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...</td>\n",
       "      <td>Honda</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...</td>\n",
       "      <td>Honda</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...</td>\n",
       "      <td>Honda</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   src  brand  label\n",
       "0    BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...    BMW      0\n",
       "1    BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...    BMW      0\n",
       "2    BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...    BMW      0\n",
       "3    BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...    BMW      0\n",
       "4    BMW_2-Series_2014_32_17_240_20_4_69_55_174_23_...    BMW      0\n",
       "..                                                 ...    ...    ...\n",
       "245  Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...  Honda      4\n",
       "246  Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...  Honda      4\n",
       "247  Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...  Honda      4\n",
       "248  Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...  Honda      4\n",
       "249  Honda_Accord_2011_25_17_190_24_4_72_56_191_22_...  Honda      4\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = []\n",
    "for i in range(len(data)):\n",
    "    label_list.append(labels_map[data[\"brand\"][i]])\n",
    "data[\"label\"] = label_list\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f9dba273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= []\n",
    "y= []\n",
    "dict_pairs = {}\n",
    "for i in range(len(data)):\n",
    "    src = data.loc[i,'src']\n",
    "    src = cv2.imread(src, cv2.IMREAD_COLOR)\n",
    "    X.append(src)\n",
    "    y.append(data.loc[i,'label'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a4a89448",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_X = super_resolution(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f77acdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx].reshape(-1,32,32)/255, np.array(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "454f8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "itera_dataset = CustomImageDataset(new_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "06310b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(itera_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([32, 1024, 32, 32])\n",
      "Image label dimensions: torch.Size([32])\n",
      "Class labels of 10 examples: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(1024, 256, kernel_size=3, stride=2, padding=1),\n",
    "                torch.nn.BatchNorm2d(256),\n",
    "                torch.nn.LeakyReLU(0.1, inplace=True),\n",
    "                #\n",
    "                torch.nn.Conv2d(256, 2048, kernel_size=3, stride=1, padding=1),\n",
    "                torch.nn.BatchNorm2d(2048),\n",
    "                torch.nn.LeakyReLU(0.1, inplace=True),\n",
    "                #\n",
    "                torch.nn.Conv2d(2048, 64, kernel_size=3, stride=2, padding=1),\n",
    "                torch.nn.BatchNorm2d(64),\n",
    "                torch.nn.LeakyReLU(0.1, inplace=True),\n",
    "                #\n",
    "                torch.nn.Flatten(),\n",
    "                torch.nn.Linear(4096, 128),\n",
    "                torch.nn.BatchNorm1d(128),\n",
    "                torch.nn.LeakyReLU(0.1, inplace=True),\n",
    "                torch.nn.Dropout(0.5),\n",
    "                #\n",
    "                torch.nn.Linear(128, 5),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = net.float()\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 86 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98f0fa53be6f2a829ff1aa00e7fe738a6b1f8ebcae1a64b50fd64e2118a16aed"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
